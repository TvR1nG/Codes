{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd  \n",
    "import nltk "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data and take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def read_dataset(split='train'):\n",
    "    path = 'IMDb'\n",
    "    \n",
    "    x, y = [], []\n",
    "    for line in open(os.path.join(path, split, 'imdb_%s_pos.txt' % split)):\n",
    "        line = line.strip()\n",
    "        x.append(line)\n",
    "        y.append(1)\n",
    "        \n",
    "    for line in open(os.path.join(path, split, 'imdb_%s_neg.txt' % split)):\n",
    "        line = line.strip()\n",
    "        x.append(line)\n",
    "        y.append(-1)\n",
    "        \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train/dev/split = 15000 5000 5000\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = read_dataset(split='train')\n",
    "x_dev, y_dev = read_dataset(split='dev')\n",
    "x_test, y_test = read_dataset(split='test')\n",
    "\n",
    "print 'number of train/dev/split =', len(y_train), len(y_dev), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepape features for ML \n",
    "\n",
    "- bow\n",
    "- tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#bow features\n",
    "from sklearn.feature_extraction.text import CountVectorizer #tokenizes and counts words\n",
    "\n",
    "# build bag of words features' vectorizer and get features\n",
    "bow_vectorizer = CountVectorizer(min_df=1, ngram_range=(1,1))\n",
    "bow_x_train = bow_vectorizer.fit_transform(x_train)\n",
    "bow_x_dev = bow_vectorizer.transform(x_dev) \n",
    "bow_x_test = bow_vectorizer.transform(x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf features\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer #alternatively, use TfidfTransformer()\n",
    "\n",
    "tfidf_vectorizer=TfidfVectorizer(min_df=1, \n",
    "                                 norm='l2',\n",
    "                                 smooth_idf=True,\n",
    "                                 use_idf=True,\n",
    "                                 ngram_range=(1,1))\n",
    "tfidf_x_train = tfidf_vectorizer.fit_transform(x_train)\n",
    "tfidf_x_dev = tfidf_vectorizer.transform(x_dev) \n",
    "tfidf_x_test = tfidf_vectorizer.transform(x_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define metrics for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# define a function to evaluate our classification models based on four metrics\n",
    "def get_metrics(true_labels, predicted_labels):\n",
    "    \n",
    "    acc = np.round(metrics.accuracy_score(true_labels, predicted_labels), 2)\n",
    "    precision = np.round(metrics.precision_score(true_labels, predicted_labels), 2)\n",
    "    recall = np.round(metrics.recall_score(true_labels, predicted_labels), 2)\n",
    "    f1_score = np.round(metrics.f1_score(true_labels, predicted_labels), 2)\n",
    "    \n",
    "    print('Accuracy  Precision  Recall    F1 score')\n",
    "    print('%8.2f %8.2f %8.2f %8.2f'%(acc, precision, recall, f1_score))\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define how to train and evaluate classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that trains the model, performs predictions and evaluates the predictions\n",
    "def train_predict_evaluate_model(classifier, \n",
    "                                 train_features, train_labels, \n",
    "                                 test_features, test_labels):\n",
    "    # build model    \n",
    "    classifier.fit(train_features, train_labels)\n",
    "    # predict using model\n",
    "    predictions = classifier.predict(test_features)\n",
    "    # evaluate model prediction performance   \n",
    "    get_metrics(true_labels=test_labels, \n",
    "                predicted_labels=predictions)\n",
    "    return predictions    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train classifers with bow features\n",
    "### use dev set for hyper-parameter finding\n",
    "\n",
    "- Multinomial NB\n",
    "- linear SVM\n",
    "- Decision Tree\n",
    "- Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.85     0.87     0.82     0.85\n"
     ]
    }
   ],
   "source": [
    "# no hyperparameters for Naive Bayes model\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "# Multinomial Naive Bayes with bag of words features\n",
    "predictions = train_predict_evaluate_model(classifier=mnb,\n",
    "                                           train_features=bow_x_train,\n",
    "                                           train_labels=y_train,\n",
    "                                           test_features=bow_x_dev,\n",
    "                                           test_labels=y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('C =', 0.0001)\n",
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.84     0.83     0.85     0.84\n",
      "('C =', 0.001)\n",
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.88     0.87     0.89     0.88\n",
      "('C =', 0.01)\n",
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.88     0.88     0.89     0.88\n",
      "('C =', 0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python27\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.88     0.87     0.88     0.88\n",
      "('C =', 0.5)\n",
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.87     0.87     0.87     0.87\n",
      "('C =', 1.0)\n",
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.87     0.87     0.87     0.87\n",
      "('C =', 5.0)\n",
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.87     0.87     0.87     0.87\n",
      "('C =', 10.0)\n",
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.86     0.86     0.87     0.87\n"
     ]
    }
   ],
   "source": [
    "# SVM with bag of words features\n",
    "# hyper-param: C, controls the tolerance of misleading points for SVM\n",
    "Clist = [1e-4, 1e-3, 1e-2, .1, .5, 1., 5., 10.]\n",
    "\n",
    "for c in Clist:\n",
    "    svm = LinearSVC(C=c)\n",
    "    print('C =', c)\n",
    "    predictions = train_predict_evaluate_model(classifier=svm,\n",
    "                                               train_features=bow_x_train,\n",
    "                                               train_labels=y_train,\n",
    "                                               test_features=bow_x_dev,\n",
    "                                               test_labels=y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('max depth =', 3)\n",
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.67     0.62     0.90     0.73\n",
      "('max depth =', 5)\n",
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.69     0.64     0.90     0.75\n",
      "('max depth =', 10)\n",
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.72     0.67     0.87     0.76\n",
      "('max depth =', 20)\n",
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.72     0.70     0.80     0.75\n",
      "('max depth =', 50)\n",
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.71     0.71     0.72     0.72\n"
     ]
    }
   ],
   "source": [
    "#Decision tree with bag of words features\n",
    "# hyper-param: max_depth, controls the maximum depth of a decision tree (too deep may lead to overfitting)\n",
    "Dlist = [3, 5, 10, 20, 50]\n",
    "\n",
    "for d in Dlist:\n",
    "    dt = DecisionTreeClassifier(max_depth=d)\n",
    "    print('max depth =', d)\n",
    "    predictions = train_predict_evaluate_model(classifier=dt,\n",
    "                                               train_features=bow_x_train,\n",
    "                                               train_labels=y_train,\n",
    "                                               test_features=bow_x_dev,\n",
    "                                               test_labels=y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('number of base estimators =', 10)\n",
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.75     0.74     0.78     0.76\n",
      "('number of base estimators =', 20)\n",
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.79     0.79     0.81     0.80\n",
      "('number of base estimators =', 50)\n",
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.82     0.81     0.83     0.82\n",
      "('number of base estimators =', 100)\n",
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.83     0.82     0.86     0.84\n",
      "('number of base estimators =', 200)\n",
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.85     0.83     0.87     0.85\n"
     ]
    }
   ],
   "source": [
    "#random forest with bag of words features\n",
    "Nlist = [10, 20, 50, 100, 200]\n",
    "\n",
    "for n in Nlist:\n",
    "    rf = RandomForestClassifier(n_estimators=n, max_depth=20)\n",
    "    print('number of base estimators =', n)\n",
    "    predictions = train_predict_evaluate_model(classifier=rf,\n",
    "                                               train_features=bow_x_train,\n",
    "                                               train_labels=y_train,\n",
    "                                               test_features=bow_x_dev,\n",
    "                                               test_labels=y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.87     0.90     0.84     0.87\n"
     ]
    }
   ],
   "source": [
    "# no hyperparameters for Naive Bayes model\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "# Multinomial Naive Bayes with tf-idf feature\n",
    "predictions = train_predict_evaluate_model(classifier=mnb,\n",
    "                                           train_features=tfidf_x_train,\n",
    "                                           train_labels=y_train,\n",
    "                                           test_features=tfidf_x_dev,\n",
    "                                           test_labels=y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('C =', 0.0001)\n",
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.73     0.85     0.56     0.67\n",
      "('C =', 0.001)\n",
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.79     0.78     0.80     0.79\n",
      "('C =', 0.01)\n",
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.84     0.82     0.86     0.84\n",
      "('C =', 0.1)\n",
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.89     0.88     0.90     0.89\n",
      "('C =', 0.5)\n",
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.90     0.89     0.91     0.90\n",
      "('C =', 1.0)\n",
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.90     0.89     0.90     0.90\n",
      "('C =', 5.0)\n",
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.89     0.88     0.90     0.89\n",
      "('C =', 10.0)\n",
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.89     0.88     0.90     0.89\n"
     ]
    }
   ],
   "source": [
    "# SVM with tf-idf feature\n",
    "# hyper-param: C, controls the tolerance of misleading points for SVM\n",
    "Clist = [1e-4, 1e-3, 1e-2, .1, .5, 1., 5., 10.]\n",
    "\n",
    "for c in Clist:\n",
    "    svm = LinearSVC(C=c)\n",
    "    print('C =', c)\n",
    "    predictions = train_predict_evaluate_model(classifier=svm,\n",
    "                                               train_features=tfidf_x_train,\n",
    "                                               train_labels=y_train,\n",
    "                                               test_features=tfidf_x_dev,\n",
    "                                               test_labels=y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('max depth =', 3)\n",
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.67     0.62     0.88     0.73\n",
      "('max depth =', 5)\n",
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.69     0.63     0.91     0.75\n",
      "('max depth =', 10)\n",
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.72     0.67     0.87     0.76\n",
      "('max depth =', 20)\n",
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.72     0.69     0.81     0.74\n",
      "('max depth =', 50)\n",
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.71     0.71     0.72     0.71\n"
     ]
    }
   ],
   "source": [
    "# Decision tree with tf-idf feature\n",
    "# hyper-param: max_depth, controls the maximum depth of a decision tree (too deep may lead to overfitting)\n",
    "Dlist = [3, 5, 10, 20, 50]\n",
    "\n",
    "for d in Dlist:\n",
    "    dt = DecisionTreeClassifier(max_depth=d)\n",
    "    print('max depth =', d)\n",
    "    predictions = train_predict_evaluate_model(classifier=dt,\n",
    "                                               train_features=tfidf_x_train,\n",
    "                                               train_labels=y_train,\n",
    "                                               test_features=tfidf_x_dev,\n",
    "                                               test_labels=y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('number of base estimators =', 10)\n",
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.74     0.74     0.76     0.75\n",
      "('number of base estimators =', 20)\n",
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.78     0.78     0.79     0.78\n",
      "('number of base estimators =', 50)\n",
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.81     0.81     0.82     0.81\n",
      "('number of base estimators =', 100)\n",
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.82     0.83     0.82     0.83\n",
      "('number of base estimators =', 200)\n",
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.83     0.83     0.84     0.84\n"
     ]
    }
   ],
   "source": [
    "#random forest with tf-idf feature\n",
    "# hyper-param: n_estimators, control to use how many base estimators to form a forest\n",
    "Nlist = [10, 20, 50, 100, 200]\n",
    "\n",
    "for n in Nlist:\n",
    "    rf = RandomForestClassifier(n_estimators=n, max_depth=20)\n",
    "    print('number of base estimators =', n)\n",
    "    # Multinomial Naive Bayes with bag of words features\n",
    "    predictions = train_predict_evaluate_model(classifier=rf,\n",
    "                                               train_features=tfidf_x_train,\n",
    "                                               train_labels=y_train,\n",
    "                                               test_features=tfidf_x_dev,\n",
    "                                               test_labels=y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test classifers\n",
    "\n",
    "### with their best parameters on the suitable features\n",
    "### and compare their performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.86     0.89     0.82     0.85\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "predictions = train_predict_evaluate_model(classifier=mnb,\n",
    "                                           train_features=tfidf_x_train,\n",
    "                                           train_labels=y_train,\n",
    "                                           test_features=tfidf_x_test,\n",
    "                                           test_labels=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.90     0.89     0.90     0.90\n"
     ]
    }
   ],
   "source": [
    "svm = LinearSVC(C=0.5)\n",
    "predictions = train_predict_evaluate_model(classifier=svm,\n",
    "                                           train_features=tfidf_x_train,\n",
    "                                           train_labels=y_train,\n",
    "                                           test_features=tfidf_x_test,\n",
    "                                           test_labels=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.73     0.67     0.88     0.76\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=10)\n",
    "predictions = train_predict_evaluate_model(classifier=dt,\n",
    "                                           train_features=bow_x_train,\n",
    "                                           train_labels=y_train,\n",
    "                                           test_features=bow_x_test,\n",
    "                                           test_labels=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  Precision  Recall    F1 score\n",
      "    0.86     0.84     0.88     0.86\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200, max_depth=20)\n",
    "predictions = train_predict_evaluate_model(classifier=rf,\n",
    "                                           train_features=bow_x_train,\n",
    "                                           train_labels=y_train,\n",
    "                                           test_features=bow_x_test,\n",
    "                                           test_labels=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future work and Discussion\n",
    "\n",
    "### Since the best classifer is SVM, we investigate it deeper.\n",
    "\n",
    "- Is it balanced for pos/neg emotion ?\n",
    "\n",
    "  - From the following block, the answer is yes.\n",
    "  \n",
    "  \n",
    "\n",
    "- Is it balanced for text with different length ?\n",
    "\n",
    "   - From the following block, the answer is also yes.\n",
    "   \n",
    "   \n",
    "So, maybe the future work includes:\n",
    "\n",
    "- Check the fairness of movie review to the movies in different topics.\n",
    "\n",
    "- Use deep leaning methods, such as word embedding, CNN or RNN for better semantic capturing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2220  281]\n",
      " [ 239 2260]]\n"
     ]
    }
   ],
   "source": [
    "svm = LinearSVC(C=0.5)\n",
    "svm.fit(tfidf_x_train, y_train)\n",
    "z = svm.predict(tfidf_x_test)\n",
    "print(metrics.confusion_matrix(y_true=y_test, y_pred=z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7.850e+02, 1.035e+03, 3.430e+02, 1.470e+02, 9.600e+01, 6.900e+01,\n",
       "        3.400e+01, 1.400e+01, 1.700e+01, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 1.000e+00]),\n",
       " array([  19.  ,  131.95,  244.9 ,  357.85,  470.8 ,  583.75,  696.7 ,\n",
       "         809.65,  922.6 , 1035.55, 1148.5 , 1261.45, 1374.4 , 1487.35,\n",
       "        1600.3 , 1713.25, 1826.2 , 1939.15, 2052.1 , 2165.05, 2278.  ]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "len_test_true = [len(x.split()) for x, y in zip(x_test, y_test) if y == 1]\n",
    "plt.hist(len_test_true, 20, color='b', alpha=0.2)\n",
    "\n",
    "len_test_pred = [len(x.split()) for x, y in zip(x_test, z) if y == 1]\n",
    "plt.hist(len_test_pred, 20, color='g', alpha=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
